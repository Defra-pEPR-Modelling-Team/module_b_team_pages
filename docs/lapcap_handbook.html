<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>LAPCAP Handbook</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
  <link rel="icon" type="image/png" href="favicon.ico"/>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="notitle.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">FPC Team Pages</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    New Starters
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="new_induction_stuff.html">Start here!</a>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">How to...</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="new_how_to_access_r_studio.html">...access R Studio</a>
        </li>
        <li>
          <a href="new_how_to_set_up_github.html">...set up Github</a>
        </li>
        <li>
          <a href="new_how_to_edit_github_code.html">...edit Github code</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
<li>
  <a href="lapcap_library.html">LAPCAP Library</a>
</li>
<li>
  <a href="lapcap_handbook.html">LAPCAP Handbook</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Other Useful Bits
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="other_glossary.html">Glossary</a>
    </li>
    <li>
      <a href="other_learning.html">Learning and Development</a>
    </li>
    <li>
      <a href="other_meeting_etiquette.html">Meeting Etiquette</a>
    </li>
    <li>
      <a href="other_common_problems.html">Common Problems</a>
    </li>
    <li>
      <a href="other_useful_links.html">Collected Links</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">LAPCAP Handbook</h1>

</div>


<div id="lapcap-handbook" class="section level1">
<h1>LAPCAP Handbook</h1>
<p>This document is a plan for model development, quality assurance and
signoff processes of LAPCAP. It includes detail on how, when and by whom
model, data or assumption changes will be assured. This includes a list
of responsibilities relating to the model, who the model owner is, the
governance structure and decision-making process supporting the
model.</p>
<p>The below diagrams give an overview of the processes, with more
detail included in later sections.</p>
<div id="coding-process" class="section level3">
<h3>Coding Process</h3>
<p><img src="assets/bible_process_1.png" /></p>
</div>
<div id="signoff-process" class="section level3">
<h3>Signoff Process</h3>
<p><img src="assets/bible_process_2.png" /></p>
</div>
<div id="stakeholder-groups" class="section level3">
<h3>Stakeholder Groups</h3>
<ul>
<li><strong>Senior Responsible Officers (SROs)</strong>
<ul>
<li>Director of Resources &amp; Waste (Emma Bourne) and equivalents in
the Devolved Administrations (David McPhee, Rhodri Asby, Shane
Doris).</li>
</ul></li>
<li><strong>pEPR Project Board</strong>
<ul>
<li>Senior level oversight and support for the delivery of the joint
UK-wide pEPR. Chaired by Dexter Davis.</li>
</ul></li>
<li><strong>Model Owner</strong>
<ul>
<li>G6 head of Fees and Payments Calculator team (Tristan Ibrahim).</li>
</ul></li>
<li><strong>Advisory Groups</strong>
<ul>
<li>Analytical Board - consists of senior analysts from England, Wales
and Scotland</li>
<li>Technical Working Group (TWG) - comprising expert waste advisors to
Defra and the devolved administrations</li>
<li>Local Authority Waste Officer Sounding Board ‚Äì selected Waste
Officers from local authorities across the UK</li>
<li>Government Actuary‚Äôs Department ‚Äì to date external QA has been
provided by GAD</li>
</ul></li>
<li><strong>Fees and Payments Calculator modelling team</strong>
<ul>
<li>Made up of members of the Government Operational Research
profession, ensuring necessary modelling skills.</li>
</ul></li>
</ul>
<p>Named individuals correct as of 3/2/2025</p>
</div>
<div id="model_versioning" class="section level3">
<h3>Model Versioning</h3>
<p>We use a process of model versioning designed to allow easy
rolling-back to past versions.</p>
<p>In version Vx.y.z</p>
<ul>
<li>The first number, x, should be updated when figures are published
externally (including publishing letters, use in public base fees
etc.)</li>
<li>The second number, y, should be updated when figures are shared
non-publically (e.g.¬†with Simpler Recycling, MHCLG, DESNZ etc.)</li>
<li>The third number, z, should be updated when there are changes to the
data inputs or the data pipeline (to allow rolling back to the correct
data in the future)</li>
</ul>
<blockquote>
<h4 id="model_tagging"><strong>How to update the tagged
version</strong></h4>
<p>When a new version of the model needs to be tagged on GitHub, follow
the below steps:</p>
<ol style="list-style-type: decimal">
<li>Create a branch from dev</li>
<li>Change the model_version parameter in <code>run_LAPCAP_model</code>
(in <code>main.R</code>) and the model_version parameter in the
data_pipeline function in <code>update_data_pipeline.R</code>. Commit
and push these changes to your branch</li>
<li>Run the data pipeline with the new model_version parameter to create
a folder on the aws bucket containing all the data for that version of
the model (remembering to restart your R session and clean your
environment before running the pipeline) - see <a
href="#how_to_data_input">here</a> for full data pipeline guidance</li>
<li>Ensure that the data pipeline and model both run correctly with the
new model_version parameter</li>
<li>Open a pull request (PR) to merge your branch back into dev</li>
<li>Merge the branch into dev (following any QA processes) and delete
the now-redundant branch</li>
<li>Tag the commit on dev with the new model version using GitHub‚Äôs
tagging feature</li>
<li>Optionally, if publishing externally and updating the first number
in the model version, you should now open a PR and merge dev into
main</li>
</ol>
<p>Ensure that the rest of the team are aware of the version being
tagged so they can rebase their branches if necessary.</p>
</blockquote>
</div>
</div>
<div id="coding-process-detail" class="section level1">
<h1>Coding Process Detail</h1>
<div id="decide-to-change-code" class="section level2">
<h2>1. Decide to change code</h2>
<p>The modelling team, led by G7s, will identify the most important
changes needed ahead of the next release of modelling outputs.</p>
<p>They may choose to make use of the Analytical Board, TWG or Sounding
Board in determining this.</p>
<p>They may also choose to seek signoff of their plans from the model
owner or project board, or to simply make them aware, to ensure planned
changes are expected.</p>
<p>An agile methodology using Jira is then used to plan out the delivery
of these changes. Time for quality assurance should
<strong>ALWAYS</strong> be built into each ticket in this planning, it
should be understood that if there is not time for quality assurance
then there is not time for the work.</p>
</div>
<div id="make-changes-to-code" class="section level2">
<h2>2. Make changes to code</h2>
<p>Through R Studio and Github changes are made to the existing LAPCAP
model. This will be achieved through standard Git practice,
e.g.¬†branching off from the dev branch. Instructions for how to do this
can be found in the <a href="new_induction_stuff.html">new starter
section</a>.</p>
<p>The changes required should be clearly laid out in the relevant Jira
ticket.</p>
<ol style="list-style-type: lower-alpha">
<li>If the changes involve adding, removing or changing an assumption
then the modelling team member must update the relevant assumption
log:</li>
</ol>
<blockquote>
<h3 id="how_to_assumption">How to change an assumption</h3>
<ol style="list-style-type: decimal">
<li><p>Identify an assumption.</p>
<p>We define assumptions as <strong>‚Äúchoices analysts make to correct
for low quality or absent data or information, that knowingly introduce
inaccuracy into our outputs.‚Äù</strong></p>
<p>Questions to help you determine whether a section of code is an
assumption could be:</p>
<ul>
<li>Have you had to make a specific choice for how to model?</li>
<li>Is your choice a simplification of reality?</li>
<li>Theoretically were there other choices you could have made?</li>
<li>Would changing your choice affect the final number?</li>
<li>Is this information recorded elsewhere (e.g.¬†in a data log or the
technical document)?</li>
</ul></li>
<li><p>Record your assumption in-code</p>
<p>Paste the following code snippet below the relevant portion of code
and edit to reflect the above.</p>
<pre class="r"><code># Assumption: Title of assumption
# Quality: RED
# Impact: AMBER
# Detailed description
# on one line or many.</code></pre>
<p>The title of the assumption should be short, clear and unique to this
assumption.</p>
<p>The RAG rating is a red, amber or green rating summarising both the
quality (e.g.¬†how confident we are) and impact (e.g.¬†how much model
outputs are likely to be affected) of the assumption.</p>
<p>The detail description should give all information needed for someone
to understand the assumption, including why an assumption is needed, why
you have made the choice and more.</p>
<p>For more info on the package behind our assumptions log go to: <a
href="https://assumptions.readthedocs.io/en/latest/index.html">Assumptions
1.1.0 Docs</a>.</p></li>
<li><p>Record your assumption in the relevant assumptions log</p>
<p>Each module has its own assumptions log which you can find via the
LAPCAP library.</p>
<p>You will need to fill out the following fields:</p>
<ul>
<li><p>ID <em>- prefilled</em></p></li>
<li><p>Assumption title <em>- same as reported in code</em></p></li>
<li><p>Detailed description <em>- same as reported in code</em></p></li>
<li><p>Reporter <em>- your name</em></p></li>
<li><p>Script(s) <em>- which R script the assumption can be found
in</em></p></li>
<li><p>Line(s) in code <em>- which lines in the script are
relevant</em></p></li>
<li><p>RAG <em>- same as reported in code</em></p></li>
<li><p>RAG explanation <em>- an explanation for why you gave the above
RAG rating</em></p></li>
<li><p>Links to supporting evidence <em>- any supporting evidence that
you used in formulating this assumption, which should be stored in the
corresponding ‚ÄòSupporting Evidence‚Äô folder</em></p></li>
</ul></li>
</ol>
</blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>If the changes involve updating a data import then the data pipeline
must be refreshed and data logs updated:</li>
</ol>
<blockquote>
<h3 id="how_to_data_input">How to modify the data pipeline</h3>
<p>We have separated the code that processes our data inputs from the
rest of the model,. this code is known as the <em>data pipeline</em>.The
data pipeline is our way of version controlling input data for LAPCAP,
meaning we can run previous versions of the model even if inputs have
changed.</p>
<p>It works by reading the raw data inputs from AWS S3, processing them
in R and then saving them back to AWS in a new version specific
location. The model can then read from this location.</p>
<p>Therefore if you need to change, add or remove a data input or the
way it is processed, you will need to edit the data pipeline. Guidance
for how to do this can be found below.</p>
<p><strong>Important:</strong></p>
<ul>
<li>When working on or updating the data pipeline itself
(experimentation, testing, logic changes etc.) or updating/changing a
data source, <strong>you <em>must</em> ensure you have changed the
model_version parameter in any calls to the data_pipeline
function</strong> ‚Äì this prevents you from accidentally overwriting data
being used by the ‚Äúlive‚Äù model and ensures rolling-back to versions is
easy in the future.</li>
<li>The pipeline will tell you if you are going to overwrite any
data.</li>
<li>You should use a unique string for your model_version parameter
e.g.¬†‚Äúyour_name_test‚Äù.</li>
<li>Once you have finished your experimentation/changes make sure to
update the model_version parameter to the correct model version number
before merging back into dev, and delete any temporary folders you
created in aws using your model_version parameter. Follow the <a
href="#model_tagging">Model Versioning guidance</a> to update the model
version and run the pipeline.</li>
</ul>
<h4 id="running-the-data-pipeline"><strong>Running the Data
Pipeline:</strong></h4>
<p>To run the data pipeline, run the <code>update_data_pipeline.R</code>
script. This will update to the latest version of the LAPCAP package,
load all of the pipeline scripts, and run the pipeline (including saving
the outputs to the aws bucket). This will create a new folder of
processed data at ‚ÄúModule_B1/Inputs/Processed/‚Äù named after the
model_version parameter.</p>
<p>There are dependencies between the sub-pipelines (e.g.¬†waste flow
using data from scheme data), so they will need to be run in order in
any experimentation.</p>
<p>If you are running pipeline functions outside of the pipeline itself,
you will likely need to define the following variables:</p>
<pre class="r"><code>s3_bucket &lt;- &quot;s3-ranch-043&quot;
root_folder &lt;- &quot;Module_B1/Inputs&quot;
file_log &lt;- list()</code></pre>
<h4
id="updating-the-processing-or-logic-in-the-data-pipeline"><strong>Updating
the processing or logic in the data pipeline:</strong></h4>
<ol style="list-style-type: decimal">
<li><p>Follow the guidance above to prevent overwriting data that is (or
will be) used</p></li>
<li><p>Experiment and make the changes needed to the code</p></li>
<li><p>Update the model_version parameter to the next model version
(following the <a href="#model_tagging">Model Versioning guidance</a>)
in both the argument to <code>data_pipeline()</code> in
<code>update_data_pipeline.R</code> and the argument to
<code>run_LAPCAP_model()</code> in <code>main.R</code></p></li>
<li><p>Run the pipeline to create a folder of data for that model
version</p></li>
<li><p>Open a PR, follow QA processes and merge your changes into
dev</p></li>
<li><p>Follow the Model Versioning guidance about tagging the new model
version on dev</p></li>
</ol>
<h4 id="updating-a-data-source"><strong>Updating a data
source:</strong></h4>
<ol style="list-style-type: decimal">
<li><p>Follow the guidance above to prevent overwriting data that is (or
will be) used</p></li>
<li><p>Experiment and make the changes needed to the code. Ensure you
add the file_path and file_log logic to any new import functions (see
the other import functions for details) ‚Äì this will capture the new data
sources in the file log.</p></li>
<li><p>Update the model_version parameter to the next model version
(following the <a href="#model_tagging">Model Versioning guidance</a>)
in both the argument to <code>data_pipeline()</code> in
<code>update_data_pipeline.R</code> and the argument to
<code>run_LAPCAP_model()</code> in <code>main.R</code></p></li>
<li><p>Run the pipeline to create a folder of data for that model
version</p></li>
<li><p>Open a PR, follow QA processes and merge your changes into
dev</p></li>
<li><p>Follow the Model Versioning guidance about tagging the new model
version on dev</p></li>
</ol>
</blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li><p>If model logic is changed then the technical document, code
comments and roxygen headers must be updated accordingly.</p>
<p>Additionally unit tests may need adding or updating.</p></li>
</ol>
<blockquote>
<h3 id="how-to-update-the-technical-document">How to update the
technical document</h3>
<p>All updates to the technical document should first be written in the
technical document working draft document. It is not neccessary for
someone to check when you have written in the doc, but of course if you
are not confident with what you have written then get someone to check.
Before any numbers are publicised all updates to the technical document
should be checked. When the word document has been fully approved, only
then should the markdown file be changed. (This is for your ease of use
as it is much easier to edit a word document).</p>
<p><strong>How to know if you should update the technical
document</strong></p>
<p>If the changes to the model you have created have changed the
functionality of the model then you should update the relevent section
of the technical document. The sections of the technical document mirror
the model modules. Furthermore, if a new calculation is added, then the
example calculations section should also be updated. Whenever a new file
in the model (not the pipeline) is created, the technical document
should also be created. Even if there is no actual changes to model
functionality, the related content section for the relevant module
should also be updated with the name of the new file created. This is
because when the markdown is created it checks that all files have been
covered in the technical document.</p>
<p><strong>Tips for wrtiting the technical document/example
calculations:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Ensure you explain the model in terms that a non-technical person
can understand</p></li>
<li><p>Use as many diagrams as possible to aid understanding</p></li>
<li><p>Use example calculations/equations</p></li>
<li><p>Don‚Äôt use any language like ‚ÄúI‚Äù or ‚Äúwe‚Äù</p></li>
<li><p>If you are not sure how to write your section then read some
other sections for guidance or ask someone to help.</p></li>
<li><p>If you are updating the example calculations section there should
be no surprises! Each variable you mention should have previously
mentioned or you need to say where it has come from.</p></li>
<li><p>All equations in example calculations should follow
through.</p></li>
</ol>
<p><strong>What happens with the technical document when we publish
numbers?</strong></p>
<p>The final technical document should be created using markdown,
however, before any changes are made to the markdown, the following must
happen:</p>
<ol style="list-style-type: decimal">
<li><p>All new files that have been covered in the updated technical
document should be added to the related contents section in the markdown
code.</p></li>
<li><p>You should run the generate technical document function to check
which files are not covered in the technical document. If it is fine for
these files to not be covered, fine, but if they include important
functionality then update the technical document.</p></li>
<li><p>The technical document should be sent to relevant parties who
want to check it. This should include the FPC team, members of adjoining
teams, the G6 (Tristan), and any other people you think might want to
add input.</p></li>
<li><p>The HTML version of the example calculations section should be
sent to the contents team to check if there are any significant changes.
This is subject to it still being included in the LA guidance and
published.</p></li>
</ol>
</blockquote>
<blockquote>
<h3 id="how_to_unit_test">How to write a unit test</h3>
<p>Unit tests are automated checks that verify individual functions or
modules behave as expected. They act as a safety net when changing or
adding features, ensuring existing functionality remains unchanged. The
tests serve as live documentation for how functions are intended to work
but also pinpoint which part of the code does not work when failing.
This section explains how to write, run, and maintain unit tests for our
LAPCAP model.¬†</p>
<p>Assuming you‚Äôve set up the correct directory and project (module_b)
you can find all unit tests in the LAPCAP model in the
~/module_b/LAPCAP/tests folder. You should be able to click on any one
of them and run them as any normal function (Ctrl+Shift+Enter). After
which the test results will appear in the ‚ÄúConsole‚Äù pane. You will see
messages like ‚ÄúTest passed‚Äù or error messages if something goes
wrong.¬†</p>
<p>If you wish to run them all at the same time you can use:
‚Äútestthat::test_dir(‚Äù~/module_b/LAPCAP/tests‚Äù)‚Äù which will execute all
the files in that location.¬†</p>
<h4 id="writing-a-unit-test">Writing a unit test</h4>
<p>Before writing or executing unit tests, it is crucial to ensure that
all functions required for testing are properly loaded. You can do this
by simply finding the function you‚Äôre seeking to make a unit test for
and all the functions that are relevant to it and running them before
starting the unit test.¬†</p>
<p>Sourcing each function individually in every test script should be
avoided (as names/location of functions may change). To avoid not having
the right function you should load all the functions at once into your
environment.¬† One effective method to do this is by loading LAPCAP as a
package, using library(LAPCAP), which makes all functions available in
your environment. Alternatively, you can use
devtools::load_all(‚Äú~/module_b/LAPCAP‚Äù) to load all the¬† functions into
your R session. As a manual way to load the functions that are in this
particular folder. If the folder or functions change location or name
than you can modify the code accordingly.</p>
<p>Unit tests generally fall into three categories.¬†¬†</p>
<ul>
<li><strong>Normal operation tests</strong>, verify the core
functionality of the code using typical inputs. <strong>Most of our
tests should be like this.</strong>¬†</li>
</ul>
<!-- -->
<ul>
<li><strong>Error fixing tests</strong>, confirm that known problematic
inputs (e.g., NAs, zeros, negatives, mismatched names) are correctly
handled or ‚Äúfixed.‚Äù</li>
</ul>
<!-- -->
<ul>
<li><strong>Error catching tests</strong>, ensure that inappropriate
inputs trigger proper error messages and stop execution as
intended.</li>
</ul>
<p>We use the testthat package in R to write and organise our unit
tests. Testthat offers a straightforward syntax for creating tests and
assertions, making it simple to check whether function outputs match
expected results.¬†¬†</p>
<p>It provides functions like expect_equal, expect_identical, and
expect_error that allow you to compare actual and expected outcomes,
check data types, and confirm that proper errors are raised under
invalid inputs.¬†</p>
<p>Make sure that testthat is installed and loaded in your testing
environment before running your tests. Furthermore, it is important to
name your test files clearly (e.g., test_inflate_costs.R,
test_align_facility.R) so that it is immediately obvious which module or
function each test is verifying.</p>
</blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>If the changes result in a functional change to the model, i.e.¬†the
changes will effect model outputs, then validation checks must be
carried out.</li>
</ol>
<blockquote>
<h3 id="how_to_validate">How to run validation checks</h3>
<ol style="list-style-type: decimal">
<li><p>Check the percentage difference between the outputs from the last
tagged version of LAPCAP and the output of whatever changes you have
made</p>
<p>Use the spreadsheet ‚Äú[model_version] model output sensitivity
testing.xlsx‚Äù on the Module B1 Sharepoint, within <a
href="https://defra.sharepoint.com/:f:/r/teams/Team1478/Extended%20Producer%20Responsibility%20for%20Packaging/07%20Fees%20and%20Payments%20Calculator/18%20Module%20B1%20-%20LA%20FNCs/04%20Bottom-up%20Modelling/00%20Model%20Master?csf=1&amp;web=1&amp;e=1jREhl">00
Model Master folder</a> &gt; [model_version]</p>
<p>Follow the instructions in the first sheet.</p>
<p>The spreadsheet automatically highlights any percentage changes above
the acceptable threshold. If values become highlighted, make sure to
check with a Grade 7 whether the need for the change justifies the
change in outputs.</p></li>
<li><p>Generate and inspect the Critical Success Factors (CSF) markdown
to ensure the change hasn‚Äôt violated any of the success factors</p>
<p>Use the function generate_validation_markdowns() in documents in the
LAPCAP repo to generate the markdown, following the instructions in the
function‚Äôs roxygen header</p>
<p>Inspect the output, ensuring that each CSF is still being met. If you
have any concerns, raise them with a G7 or above.</p>
<p>Download a version of the output so you can link it in the pull
request template later.</p></li>
</ol>
</blockquote>
<p>Locations for assumption log, data log or the technical document can
be found in the LAPCAP library, and each includes instructions for how
to use it.</p>
<blockquote>
<h3 id="how_to_pull_request">How to make a pull request</h3>
<p>Once the modelling team member has completed their changes, they
should make a pull request and request a review from another member of
the team.</p>
<p>Here are the <strong>step-by-step instructions</strong> to submit a
pull request:</p>
<ol style="list-style-type: decimal">
<li><p>Go to the relevant repo on Github and navigate to your branch</p>
<ol style="list-style-type: lower-alpha">
<li><p>Use either the branches drop down or click on ‚Äò<em>x
branches</em>‚Äô to go to the branches page and select your branch.</p>
<p><img src="assets/branches_button.png" /></p></li>
</ol></li>
<li><p>If your push was recent there may be a pop up allowing you to
‚Äò<em>compare and pull request</em>‚Äô, if not then click
‚Äò<em>Contribute</em>‚Äô and ‚Äò<em>Open pull request</em>‚Äô.</p>
<p><img src="assets/contribute_button.png" /></p></li>
<li><p>Now check your pull request is set up correctly:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Make sure you are merging to the correct branch, this will
usually be <em>dev</em> (for code in development) or sometimes
<em>main</em> if it has been fully quality assured.</p>
<p><img src="assets/merge_to_dev.png" /></p></li>
<li><p>Fill out the pull request template (following carrying out
validation checks, see below), including adding any additional QA checks
to the list.</p>
<p>Replace this gif with one that describes how you felt about
completing this ticket:</p>
<p><img src="https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExaHB0bHQ4dzQ4anN5b3JoaDIyb2twOXh4Y3U5YWY1NHB6c3dreWdvNSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/gOfSjdLRr6SlvGQTe3/giphy.gif" height="150"/></p>
<p>‚úîÔ∏è <strong>QA checklists</strong></p>
<p>üìù <strong>Description of changes made:</strong></p>
<p>üéüÔ∏è <strong>Link to Jira ticket:</strong></p>
<p>ü§î <strong>Link to QA log (assumptions or data log), if
changed:</strong></p>
<p>üíæ <strong>If appropriate, link to CSF markdown:</strong></p>
<p>üìà <strong>If appropriate, link to output percentage change
spreadsheet:</strong></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>% change in EPR Total Net Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Mean absolute change per LA</strong></td>
<td></td>
</tr>
<tr class="even">
<td><strong>Overall</strong></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>England</strong></td>
<td></td>
</tr>
<tr class="even">
<td><strong>Scotland</strong></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Wales</strong></td>
<td></td>
</tr>
<tr class="even">
<td><strong>NI</strong></td>
<td></td>
</tr>
</tbody>
</table>
<p>üåú <strong>Do-er QA checklist</strong></p>
<p>Before submitting a pull request the principle analyst
<strong>must</strong> have completed the below checks.</p>
<ul class="task-list">
<li><label><input type="checkbox" />Assumptions log has been updated
with any new or changed assumptions, including appropriate rationale
and/or evidence</label></li>
<li><label><input type="checkbox" />Data log has been updated with any
new or changed data</label></li>
<li><label><input type="checkbox" />If functional changes have been made
to code, the CSF markdown has been generated and inspected, and there
are no issues highlighted in visualisations</label></li>
<li><label><input type="checkbox" />If functional changes have been made
to code, the percentage change in model outputs has been calculated and
reported above, if the change is above threshold, this has been raised
with a Grade 7 or above.</label></li>
<li><label><input type="checkbox" />If additional checks are required,
these have been added to the Checker Checklist below, with detailed
instructions as to how to run the checks</label></li>
</ul></li>
<li><p>Click ‚Äò<em>Reviewer</em>‚Äô and select the person who has agreed to
review your code.</p>
<p><img src="assets/reviewers.png" /></p></li>
<li><p>Make sure you have completed the requirements and fill out the
fields in the pull request template.</p></li>
</ol></li>
<li><p>Then you can click ‚Äò<em>Create pull request</em>‚Äô.</p>
<ol style="list-style-type: lower-alpha">
<li>Once you have created the pull request you should move the ticket to
‚ÄòFor Review‚Äô on Jira.</li>
</ol></li>
</ol>
</blockquote>
</div>
<div id="verify-the-changes" class="section level2">
<h2>3. Verify the changes</h2>
<p>Once assigned a review the team member must complete the full
checklist provided by the principle analyst. It is also the QAers must
also review the list critically and ensure that it is both appropriate
and sufficient. If the QAer feels otherwise they must raise this with in
the first instance the principle analyst and then failing this the model
owner.</p>
<p>You should use the checklist below, which is also included in the
pull request template, to ensure you carry out all necessary checks:</p>
<blockquote>
<p>üåõ <strong>Checker QA checklist</strong></p>
<p>Before approving a pull request the reviewer <strong>must</strong>
have completed the below checks: In addition to the above, the following
is a checklist for the reviewer to use:</p>
<ul class="task-list">
<li><p><label><input type="checkbox" />The ‚Äúdo-er‚Äù checklist has been
completed to an appropriate standard, fields above the checklist have
been appropriately completed</label></p></li>
<li><p><label><input type="checkbox" />Code meets the requirements set
out in the Jira ticket</label></p></li>
<li><p><label><input type="checkbox" />All functions have roxygen
headers with <span class="citation">@description</span>, <span
class="citation">@param</span> and <span class="citation">@return</span>
fields, and comments in code are appropriate and
sufficient</label></p></li>
<li><p><label><input type="checkbox" />The code runs when using an empty
R environment, without error</label></p></li>
<li><p><label><input type="checkbox" />Code follows the <a
href="https://style.tidyverse.org/">tidyverse</a> and <a
href="https://defra-pepr-modelling-team.github.io/module_b_team_pages/index.html">FPC
style guide</a>.</label></p></li>
<li><p><label><input type="checkbox" />No future risks have introduced
by this change e.g.¬†hardcoded values that may change in the future, or
if they have they are adequately signposted and
justified</label></p></li>
<li><p><label><input type="checkbox" />Code cannot be simplified
significantly, there is no redundancy in code and no changes to model
structure and dependant functions are needed, given the
changes.</label></p></li>
<li><p><label><input type="checkbox" />There are no further improvements
that can be made to the code</label></p></li>
<li><p><label><input type="checkbox" />Any additional QA checks
appropriate to, and sufficient for, the changes have been
performed</label></p></li>
<li><p><label><input type="checkbox" />When submitting the final review,
a comment has been left that summarises the QA checks that have been
performed and the outcomes</label></p></li>
</ul>
</blockquote>
<p>Also you should carry out any additional checks required, which have
been added to the Checker Checklist by the doer.</p>
<p>Reviewers should trace the full logic of the code, both by reading
through it and by running it and spot-checking intermediate data frames.
They should inspect any relevant data imports both in R Studio and
directly from their original source. They should examine model outputs
before and after the changes to ensure they make sense. They should make
sure they are able to replicate any processes or calculations in the
code.</p>
<blockquote>
<p><strong>Additional checks</strong></p>
<p>The below is a list of QA checks that reviewers may want to perform
in addition to the above. Note that this lists is <strong>not
exhaustive</strong> and it is the responsibility of the principle
analyst (do-er) and the QAer (checker) to ensure all items that need to
be checked have been:</p>
<p>1. Check that the calculations done are fit for purpose and are
correct</p>
<p>2. Check that uncertainty has been considered and appropriately
accounted for (e.g.¬†has sensitivity analysis been performed)</p>
<p>3. Check that the data used is fit for purpose and the best option
available to us</p>
<p>4. Check that other appropriate documentation has been completed or
updated to an appropriate standard e.g.¬†the technical document</p>
<p>5. Is the data being correctly pulled into the model?</p>
<p>6. Is the data being properly cleaned and manipulated (either before
the model or during the code)?</p>
<p>7. Has the data been verified and validated? Has it been checked for
potential errors? And has it been confirmed that the data appropriate to
use in the first place? Is it the best possible option?</p>
<p>8. Are there other results other than the outputs of the last model
that the results need to be compared to?</p>
<p>9. In cases where new data is added, or a change is heavily dependent
upon a particular data source, does the model respond as expected to
extreme values, negatives, zeroes, NAs etc? Is it possible to break the
model with the data or generate impossible results?</p>
</blockquote>
<p>Reviewers should leave comments via GitHub, to ensure a record of
verification and validation. GitHub has several features to help with
this such as filtering changes by commit or file type, marking scripts
as viewed, making direct code suggestions and bundling many comments
into one review.</p>
<p>These reviews may go through one or more cycles of requesting
changes, in order for the reviewer to be happy. GitHub has functionality
to enable this.</p>
<p>The following explains the practical steps followed in when reviewing
code:</p>
<blockquote>
<h3 id="how_to_code_review">How to do a code review</h3>
<p>This <a href="https://www.youtube.com/watch?v=lSnbOtw4izI">Github
code review tutorial</a> shows you how to review a pull request, or you
can follow the steps below.</p>
<p>Follow these step-by-step instructions to do a proper code
review:</p>
<ol style="list-style-type: decimal">
<li><p>Navigate to the ‚Äò<em>pull request</em>‚Äô that has been assigned to
you. Read the description provided and use the checklist to aid your
review.</p></li>
<li><p>Switch to the ‚Äò<em>Files changed</em>‚Äô tab to see the changes
made, here you can make comments and suggestions as you see fit by
clicking the blue plus to the left of the line you want to comment
on.</p>
<p><img src="assets/add_comment_button.png" /></p>
<ol style="list-style-type: lower-alpha">
<li>Make sure to tick ‚Äò<em>Start a review</em>‚Äô rather than ‚Äò<em>Add
single comment</em>‚Äô.</li>
<li>Github has lots of functionality to make this process easier,
including being able to mark scripts as ‚Äò<em>Viewed</em>‚Äô and limiting
changes to certain commits.</li>
<li>You should also run the code in R Studio and check the relevant QA
log has been updated.</li>
</ol></li>
<li><p>When you are ready click ‚Äò<em>Finish your review</em>‚Äô add a
summary comment and then click ‚Äò<em>Submit review</em>‚Äô. You may choose
to leave comments to be responded to, suggest changes to be made or
simply approve the pull request straight away.</p>
<p><img src="assets/finish_review.png" width="311"
height="222" /></p></li>
</ol>
</blockquote>
<p>The QAer should then write a summary of the checks performed. In
particular noting issues and any unusual checks that have had to be
performed in the process of QAing.</p>
</div>
<div id="merge-changes-into-dev-branch" class="section level2">
<h2>4. Merge changes into dev branch</h2>
<p>Once approved, changes should be merged into the dev branch. This may
require resolving merge conflicts.</p>
<blockquote>
<h3 id="how-to-merge">How to merge</h3>
<ol style="list-style-type: decimal">
<li><p>Once your reviewer has inspected your code they may ask you some
questions or suggest some changes. Once you have responded to these they
will approve your pull request and you can merge your changes! This will
look like:</p>
<p><img src="assets/passed_pr_check.png" /></p>
<p><strong>Note</strong>: if any of the QA checklist items have been
left unchecked, GitHub will automatically block merging. It will look
like:</p>
<p><img src="assets/failed_pr_check.png" /></p></li>
<li><p>You will need to check there are no ‚Äòmerge conflicts‚Äô. This is
where someone has changed the same files as you and so you need to agree
with that person what are the correct changes and modify accordingly,
Github will read ‚Äò<em>Able to merge</em>‚Äô indicating there are no
conflicts.</p>
<p><img src="assets/ready_to_merge.png" /></p></li>
</ol>
</blockquote>
<p>Finally the QA analyst (or the appropriate G7) will review the pull
requests on a weekly basis to ensure that they been done to a high
standard.and record them in the verification log <a
href="https://defra.sharepoint.com/:x:/r/teams/Team1478/Extended%20Producer%20Responsibility%20for%20Packaging/07%20Fees%20and%20Payments%20Calculator/18%20Module%20B1%20-%20LA%20FNCs/04%20Bottom-up%20Modelling/00%20Model%20Master/03%20LAPCAP%20Signoff%20Log.xlsm?d=w5065d9665d34493c92e1fca1ce67b2fd&amp;csf=1&amp;web=1&amp;e=3xjNJt">03
LAPCAP Signoff Log.xlsm</a>. This will allow us to effectively
communicate the steps taken to ensure quality with stakeholders and
inspire confidence.</p>
</div>
</div>
<div id="signoff-process-detail" class="section level1">
<h1>Signoff Process Detail</h1>
<div id="model-development-complete" class="section level2">
<h2>1. Model development complete</h2>
<p>Once all changes required for a publication or sharing of the model
are complete, the team will undertake the following steps.</p>
<p>Multiple pull requests will have been merged into dev (e.g.¬†the above
coding process will have been repeated multiple times) and these will
all receive signoff together.</p>
<p>There are some circumstances where the full signoff may not be
required for instance, sharing the model internally, this is left to the
judgment of the model owner.</p>
</div>
<div id="model-owner-signoff" class="section level2">
<h2>2. Model owner signoff</h2>
<p>The <a
href="https://defra.sharepoint.com/:w:/r/teams/Team1478/Extended%20Producer%20Responsibility%20for%20Packaging/07%20Fees%20and%20Payments%20Calculator/18%20Module%20B1%20-%20LA%20FNCs/04%20Bottom-up%20Modelling/00%20Model%20Master/TEMPLATE%20model_owner_signoff_request.docx?d=w3162a6ece2984a77a4403747dbffba47&amp;csf=1&amp;web=1&amp;e=XhXJPj">TEMPLATE
model_owner_signoff_request.docx</a> should be used to request a sign
off from the model owner. It contains instructions for how to fill it
out.</p>
<p>The model owner should sign off on the following documents, which
should have been updated:</p>
<ul>
<li><p>Documentation</p>
<ul>
<li><p>Technical document</p></li>
<li><p>Assumptions logs &amp; accompanying evidence</p></li>
<li><p>Data logs</p></li>
<li><p>Verification log compiled by quality assurance lead</p></li>
</ul></li>
<li><p>Outputs</p>
<ul>
<li><p>Change log</p></li>
<li><p>Critical success factors markdown - which can be updated
following the steps under <a href="#how_to_validate">How to run
validation checks</a></p></li>
<li><p>The validation markdown - STILL BEING REVISED BY CAT</p></li>
</ul></li>
</ul>
<p>The model owner does not necessarily have to review all of these
themselves; they may utilise the advisory groups to offer assurance. For
instance, in the past TWG have assured on assumptions logs.</p>
<p>The model owner‚Äôs signoff for that model version should be recorded
in <a
href="https://defra.sharepoint.com/:x:/r/teams/Team1478/_layouts/15/Doc.aspx?sourcedoc=%7B5065D966-5D34-493C-92E1-FCA1CE67B2FD%7D&amp;file=TEMPLATE%20modulename%20assumptions_data_log1.xlsm&amp;action=default&amp;mobileredirect=true">03
LAPCAP Signoff Log</a>.</p>
</div>
<div id="sro-signoff" class="section level2">
<h2>3. SRO signoff</h2>
<p>Project board, acting on behalf of the model SROs, should signoff the
model version for publication.</p>
<p>It is unlikely that members of project board will review any of the
model or its documentation themselves, however copies should be shared
so they have the option to, and can delegate to members of their
organisation.</p>
<p>Instead, summaries of changes, visualisations of overall outputs and
assurances from advisory groups may be presented. Exactly what is
required may depend on the specific changes being signed off, so is left
up to the judgment of the model owner.</p>
<p>There may be an additional stage of parameter setting, at this point
in the approvals process, especially for the first outputs for each new
year of EPR.</p>
<p>The project board signoff for that model version should be recorded
in <a
href="https://defra.sharepoint.com/:x:/r/teams/Team1478/_layouts/15/Doc.aspx?sourcedoc=%7B5065D966-5D34-493C-92E1-FCA1CE67B2FD%7D&amp;file=TEMPLATE%20modulename%20assumptions_data_log1.xlsm&amp;action=default&amp;mobileredirect=true">03
LAPCAP Signoff Log</a>.</p>
</div>
<div id="share-or-publish-outputs" class="section level2">
<h2>4. Share or publish outputs</h2>
<p>Once signed off and ready to share the dev branch should be merged
into main, tagged and versioned. External publication versions should
have the first version number update e.g.¬†V5.2.1 becomes V6.0.0. The
model master folder should be updated accordingly.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
