---
title: "Coding Environment"
---

We use Defra's **Scientific Coding Environment** which allows us to write and run code on Amazon Web Service (AWS) EC2 virtual machines, and store our data using Amazon Web Services S3. Speak to the SCE admins (Ope and Jake as of September 2023) if you are not set up on the SCE.

We can use [R Studio on our virtual machine](http://ranch-479.int.sce.network/rstudio/). This is available 5am - 11pm daily. 

# How to login to AWS 

To login to AWS you just need to enter the username and password the SCE team sent you. Your username will be in the format firstnamelastname.

Login is here, at the [AWS console](http://aws-sso.sce.network/)

If you encounter problems, you may need to switch role to the RANCH account using the menu in the top right corner of the page (official docs):

1. Ranch account number: 172974337612 

2. Role name is ExtendedProducerResponsibility

3. Display name can be anything you like

4. Once logged in, you may also need to set the region to Ireland (AKA eu-west-1)

# S3

S3 is accessed through the [AWS console](https://int-sce-network.awsapps.com/console). When we upload, modify or delete data on S3, this must be recorded in the [Data Log](https://defra.sharepoint.com/:x:/r/teams/Team1478/_layouts/15/Doc.aspx?sourcedoc=%7B2FCDCE89-3F0D-41DD-B451-CB0D77D8DA26%7D&file=Data%20Log%20Ranch_479.xlsx&action=default&mobileredirect=true).

**All data** should be stored in the appropriate B1 or B2 folder at: *s3://s3-ranch-043/Module_B1/* or *s3://s3-ranch-043/Module_B2/*.

Within each of these there should be the following folders:
-   Inputs - for any raw data input to the model (this should be read only)
-   Intermediaries - for any useful data produced during modelling
-   Outputs - for the final model outputs
-   QA - for any data specifically relating to QA

Scripts for reading and writing to AWS can be found in the [useful scripts repo](https://github.com/Defra-pEPR-Modelling-Team/useful_scripts/blob/main/AWS%20to%20R.Rmd). Here is an example of **reading** an **Excel** file:
```{r AWS read, eval = FALSE}
excel_data <- aws.s3::s3read_using(
  FUN = openxlsx::read.xlsx,
  object = "test_folder/test_data.xlsx", # this file exists, but replace with your own filepath
  sheet="Sheet1",
  fillMergedCells = TRUE,
  bucket = "s3-ranch-043")
```

